{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbcc0bd83bb1f042",
   "metadata": {},
   "source": [
    "# Labo 5 Modèle word2vec et ses applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7fbbc1e9dccc7b",
   "metadata": {},
   "source": [
    "## 1. Tester et évaluer un modèle déjà entraîné sur Google News\n",
    "\n",
    "Veuillez télécharger le modèle word2vec pré-entraîné sur le corpus Google News en écrivant :\n",
    "```python\n",
    "from gensim import downloader as api\n",
    "w2v_vectors = api.load(\"word2vec-google-news-300\")\n",
    "```\n",
    "ce qui téléchargera le fichier la première fois.\n",
    "Après avoir téléchargé le modèle, vous pourrez l’utiliser ainsi (dans le dossier gensim-data) :\n",
    "```python\n",
    "from gensim.models import KeyedVectors\n",
    "w2v_vectors = KeyedVectors.load_word2vec_format(path_to_file, binary=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4530a77693e4874d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes ~30min to download. Only execute once\n",
    "from gensim import downloader as api\n",
    "w2v_vectors = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8647e6f564f562f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:38:31.774152Z",
     "start_time": "2025-05-08T12:38:31.768781Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model is then located at home directory, adjust as needed.\n",
    "import os\n",
    "file_path = os.path.join(os.path.expanduser(\"~\"), \"gensim-data\", \"word2vec-google-news-300\", \"word2vec-google-news-300.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d45bdf54f53e0683",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:39:19.093828Z",
     "start_time": "2025-05-08T12:38:32.452761Z"
    }
   },
   "outputs": [],
   "source": [
    "# Takes ~1min\n",
    "from gensim.models import KeyedVectors\n",
    "w2v_vectors = KeyedVectors.load_word2vec_format(file_path, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d924d3db2ec796",
   "metadata": {},
   "source": [
    "### a. Quelle place en mémoire occupe le processus du notebook avec les vecteurs de mots ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fc958485998331c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:37:04.190320Z",
     "start_time": "2025-05-08T12:37:04.185633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of the notebook process: 1417.81 MB\n",
      "Word2vec model size: 3433.23 MB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "import os\n",
    "\n",
    "# Get the current process ID\n",
    "process = psutil.Process(os.getpid())\n",
    "\n",
    "# Get memory information in bytes and convert to MB\n",
    "memory_info = process.memory_info()\n",
    "memory_usage_mb = memory_info.rss / 1024 / 1024  # Convert to MB\n",
    "\n",
    "print(f\"Memory usage of the notebook process: {memory_usage_mb:.2f} MB\")\n",
    "print(f\"Word2vec model size: {w2v_vectors.vectors.nbytes / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89510d7b01319c03",
   "metadata": {},
   "source": [
    "### b. Quelle est la dimension de l’espace vectoriel dans lequel les mots sont représentés ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beaa4ea8c5d8a78e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:37:08.566263Z",
     "start_time": "2025-05-08T12:37:08.562692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector dimension: 300\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vector dimension: {w2v_vectors.vector_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79739b63d4205b39",
   "metadata": {},
   "source": [
    "### c. Quelle est la taille du vocabulaire connu du modèle ? Veuillez afficher cinq mots anglais qui sont dans le vocabulaire et deux qui ne le sont pas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e98e17edd81a3fca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:37:10.026031Z",
     "start_time": "2025-05-08T12:37:10.019162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 3000000\n",
      "\n",
      "Five words in vocabulary:\n",
      "'baste' is in vocabulary\n",
      "'spleen' is in vocabulary\n",
      "'maudlin' is in vocabulary\n",
      "'saudade' is in vocabulary\n",
      "'aa' is in vocabulary\n",
      "\n",
      "Two words not in vocabulary:\n",
      "'enneahedron' is NOT in vocabulary\n",
      "'petrichor' is NOT in vocabulary\n"
     ]
    }
   ],
   "source": [
    "# Get vocabulary size\n",
    "vocab_size = len(w2v_vectors)\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "\n",
    "# Five words in vocabulary\n",
    "words_in_vocab = ['baste', 'spleen', 'maudlin', 'saudade', 'aa']\n",
    "print(\"\\nFive words in vocabulary:\")\n",
    "for word in words_in_vocab:\n",
    "    if word in w2v_vectors:\n",
    "        print(f\"'{word}' is in vocabulary\")\n",
    "    else:\n",
    "        print(f\"'{word}' is NOT in vocabulary\")\n",
    "\n",
    "# Two words not in vocabulary\n",
    "words_not_in_vocab = ['enneahedron', 'petrichor']\n",
    "print(\"\\nTwo words not in vocabulary:\")\n",
    "for word in words_not_in_vocab:\n",
    "    if word in w2v_vectors:\n",
    "        print(f\"'{word}' is in vocabulary\")\n",
    "    else:\n",
    "        print(f\"'{word}' is NOT in vocabulary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3b8cf0b8f09c6c",
   "metadata": {},
   "source": [
    "### d. Quelle est la similarité entre les mots rabbit et carrot ? Veuillez rappeler comment on mesure les similarités entre deux mots grâce à leurs vecteurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3928ca04ad311dce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:37:11.858527Z",
     "start_time": "2025-05-08T12:37:11.852660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'rabbit' and 'carrot': 0.3631\n"
     ]
    }
   ],
   "source": [
    "similarity = w2v_vectors.similarity('rabbit', 'carrot')\n",
    "print(f\"Similarity between 'rabbit' and 'carrot': {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf72ee993cf593a2",
   "metadata": {},
   "source": [
    "> La distance cosinus mesure la différence entre deux vecteurs en évaluant l'angle qui les sépare. Pour la calculer, on détermine la similitude cosinus, qui est le rapport entre le produit de ces vecteurs et le produit de leurs longueurs. Ici, la distance est de 0.3631. Puisque le cosinus a des valeurs entre -1 et 1 (1 signifie que les deux vecteurs sont identiques et -1 signifie qu'ils sont opposés), on peut dire ici que les deux mots sont assez proches mais pas énormément."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8259a27d4140edbe",
   "metadata": {},
   "source": [
    "### e. Considérez au moins 5 paires de mots anglais, certains proches par leurs sens, d’autres plus éloignés. Pour chaque paire, calculez la similarité entre les deux mots. Veuillez indiquer si les similarités obtenues correspondent à vos intuitions sur la proximité des sens des mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76e8e48ac1c3d37d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:37:14.791984Z",
     "start_time": "2025-05-08T12:37:14.785808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'king' and 'queen': 0.6511\n",
      "Similarity between 'rabbit' and 'bunny': 0.6440\n",
      "Similarity between 'rabbit' and 'hare': 0.6115\n",
      "Similarity between 'plane' and 'tower': 0.2549\n",
      "Similarity between 'duc' and 'duchesse': 0.3245\n"
     ]
    }
   ],
   "source": [
    "pairs = [\n",
    "    ('king', 'queen'),\n",
    "    ('rabbit', 'bunny'),\n",
    "    ('rabbit', 'hare'),\n",
    "    ('plane', 'tower'),\n",
    "    ('duc', 'duchesse')\n",
    "]\n",
    "\n",
    "for pair in pairs:\n",
    "    word1, word2 = pair\n",
    "    if word1 in w2v_vectors and word2 in w2v_vectors:\n",
    "        similarity = w2v_vectors.similarity(word1, word2)\n",
    "        print(f\"Similarity between '{word1}' and '{word2}': {similarity:.4f}\")\n",
    "    else:\n",
    "        print(f\"One or both words in the pair '{pair}' are not in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4951989ff91ba049",
   "metadata": {},
   "source": [
    "> Les similarités cosinus calculées pour les paires de mots correspondent en grande partie à l'intuition que nous avons de leur proximité :\n",
    "\n",
    " - 'King' et 'Queen' (0.6511) : Une similarité élevée qui reflète leur relation étroite en tant que termes royaux liés par leur rôle.\n",
    "\n",
    " - 'Rabbit' et 'Bunny' (0.6440) : Une similarité élevée qui est logique, car ce sont des termes souvent utilisés pour désigner le même animal.\n",
    "\n",
    " - 'Rabbit' et 'Hare' (0.6115) : Une similarité notable, car ce sont deux animaux très similaires même s'ils représentent des espèces différentes.\n",
    "\n",
    " - 'Plane' et 'Tower' (0.2549) : Une similarité faible, ce qui est conforme à notre intuition, car ce sont deux concepts très différents, l’un étant un moyen de transport et l’autre une structure.\n",
    "\n",
    " - 'Duc' et 'Duchesse' (0.3245) : Une similarité relativement faible, ce qui est surprenant, car ces deux termes sont des titres de noblesse étroitement liés. Cela pourrait indiquer une faible représentation de ces termes dans le modèle utilisé, ou une distinction plus marquée entre les genres.\n",
    "\n",
    "Dans l'ensemble, les valeurs correspondent globalement à nos intuitions, bien que la similarité entre 'Duc' et 'Duchesse' semble sous-estimée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df9c32c1020cc2",
   "metadata": {},
   "source": [
    "### f. Pouvez-vous trouver des mots de sens opposés mais qui sont proches selon le modèle ? Comment expliquez-vous cela ? Est-ce une qualité ou un défaut du modèle word2vec ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b94799ffa7d27059",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:37:17.434268Z",
     "start_time": "2025-05-08T12:37:17.430057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.8092\n"
     ]
    }
   ],
   "source": [
    "similarity = w2v_vectors.similarity('black', 'white')\n",
    "print(f\"Similarity: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe7e73112415bfb",
   "metadata": {},
   "source": [
    "> La similarité élevée (0.8092) entre 'black' et 'white' dans Word2Vec s'explique par le fait que ces deux mots apparaissent souvent dans des contextes similaires, comme des descriptions de couleurs, des oppositions dans des expressions ou des concepts. Word2Vec capture les relations contextuelles plutôt que les significations, ce qui entraîne une proximité vectorielle même pour des antonymes. Cela montre que le modèle est efficace pour identifier les liens contextuels entre les mots, mais qu'il ne différencie pas les synonymes des antonymes, ce qui peut être un inconvénient dans certaines applications qui nécessitent une compréhension des sens opposés."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bab382b5159fd4",
   "metadata": {},
   "source": [
    "### g. En vous aidant de la documentation de Gensim sur KeyedVectors, obtenez les scores du modèle word2vec sur les données de test WordSimilarity-353. Veuillez rappeler en 1-2 phrases comment les différents scores sont calculés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3aa6ea7a573d85c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:37:20.104140Z",
     "start_time": "2025-05-08T12:37:19.904916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.6239\n",
      "Pearson correlation p-value: 0.0000\n",
      "Spearman rank correlation coefficient: 0.6589\n",
      "Spearman rank correlation p-value: 0.0000\n",
      "Ratio of pairs with OOV words: 0.00%\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath\n",
    "\n",
    "word_sim_353_path = datapath('wordsim353.tsv')\n",
    "result = w2v_vectors.evaluate_word_pairs(word_sim_353_path)\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {result[0][0]:.4f}\")\n",
    "print(f\"Pearson correlation p-value: {result[0][1]:.4f}\")\n",
    "print(f\"Spearman rank correlation coefficient: {result[1][0]:.4f}\")\n",
    "print(f\"Spearman rank correlation p-value: {result[1][1]:.4f}\")\n",
    "print(f\"Ratio of pairs with OOV words: {result[2]:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8da2fda5367591",
   "metadata": {},
   "source": [
    "> Les scores de similarité entre les paires de mots sont évalués avec deux méthodes : le coefficient de corrélation de Pearson, qui mesure la corrélation linéaire entre les similarités prédites par le modèle et les similarités humaines, et le coefficient de corrélation de Spearman, qui évalue la cohérence des rangs (classements) des paires de mots. Les p-valeurs associées indiquent la significativité statistique de ces corrélations, tandis que le ratio de paires avec des mots hors vocabulaire (OOV) montre la proportion de paires que le modèle n'a pas pu évaluer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ec3e208878055c",
   "metadata": {},
   "source": [
    "### h. En vous aidant de la documentation, calculez le score du modèle word2vec sur les données questions-words.txt. Attention, cette évaluation prend une dizaine de minutes, donc il vaut mieux commencer par tester avec un fragment de ce fichier (copier/coller les 100 premières analogies). Expliquez en 1-2 phrases comment ce score est calculé et ce qu’il mesure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18831db6d37e4dd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:48:33.557608Z",
     "start_time": "2025-05-08T12:39:26.512857Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy: 0.7401\n",
      "Number of sections: 15\n",
      "Evaluation time: 156.10 seconds\n",
      "\n",
      "Section-wise results:\n",
      "Section 'capital-common-countries': 0.8320 accuracy (421/506)\n",
      "Section 'capital-world': 0.8132 accuracy (3552/4368)\n",
      "Section 'currency': 0.2847 accuracy (230/808)\n",
      "Section 'city-in-state': 0.7211 accuracy (1779/2467)\n",
      "Section 'family': 0.8617 accuracy (436/506)\n",
      "Section 'gram1-adjective-to-adverb': 0.2923 accuracy (290/992)\n",
      "Section 'gram2-opposite': 0.4347 accuracy (353/812)\n",
      "Section 'gram3-comparative': 0.9129 accuracy (1216/1332)\n",
      "Section 'gram4-superlative': 0.8797 accuracy (987/1122)\n",
      "Section 'gram5-present-participle': 0.7850 accuracy (829/1056)\n",
      "Section 'gram6-nationality-adjective': 0.9018 accuracy (1442/1599)\n",
      "Section 'gram7-past-tense': 0.6538 accuracy (1020/1560)\n",
      "Section 'gram8-plural': 0.8701 accuracy (1159/1332)\n",
      "Section 'gram9-plural-verbs': 0.6816 accuracy (593/870)\n",
      "Section 'Total accuracy': 0.7401 accuracy (14307/19330)\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Load questions-words.txt from gensim (path is : /.venv/lib/python3.12/site-packages/gensim/test/test_data/questions-words.txt\n",
    "analogies_path = datapath('questions-words.txt')\n",
    "#analogies_path = \"./questions-words-smaller.txt\"\n",
    "\n",
    "# Example of result : (0.0, [ {'section': 'capital-common-countries', 'correct': [], 'incorrect':[...]} ] )\n",
    "result = w2v_vectors.evaluate_word_analogies(analogies_path)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Total accuracy: {result[0]:.4f}\")\n",
    "print(f\"Number of sections: {len(result[1])}\")\n",
    "print(f\"Evaluation time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "print(\"\\nSection-wise results:\")\n",
    "for res in result[1]:\n",
    "    correct_nbr = len(res[\"correct\"])\n",
    "    total_nbr = correct_nbr + len(res[\"incorrect\"])\n",
    "    print(f\"Section '{res[\"section\"]}': {correct_nbr/total_nbr:.4f} accuracy ({correct_nbr}/{total_nbr})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f57085",
   "metadata": {},
   "source": [
    "> Le score du modèle Word2Vec sur les analogies est calculé en mesurant la proportion de questions correctement résolues parmi les analogies testées. Chaque analogie suit le format \"A est à B ce que C est à ?\", et le modèle tente de deviner le mot D. Le score mesure la capacité du modèle à capturer des relations sémantiques entre les mots (comme les relations entre capitales et pays, comparatifs, ou opposés)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b61a019db22f42",
   "metadata": {},
   "source": [
    "## 2. Entraîner deux nouveaux modèles word2vec à partir de deux corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfc3d1cc321d9c1",
   "metadata": {},
   "source": [
    "### a. En utilisant gensim.downloader (voir question 1) récupérez le corpus qui contient les 108 premiers caractères de Wikipédia (en anglais) avec la commande : corpus = api.load('text8'). Combien de phrases et de mots (tokens) possède ce corpus ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f64562501f2e437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de phrases : 1701\n",
      "Nombre de mots (tokens) : 17005207\n"
     ]
    }
   ],
   "source": [
    "corpus = api.load('text8')\n",
    "sentences = list(corpus)\n",
    "\n",
    "num_sentences = len(sentences)\n",
    "num_tokens = sum(len(sentence) for sentence in sentences)\n",
    "\n",
    "print(f\"Nombre de phrases : {num_sentences}\")\n",
    "print(f\"Nombre de mots (tokens) : {num_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b591ad",
   "metadata": {},
   "source": [
    "### b. Entraînez un nouveau modèle word2vec sur ce nouveau corpus (voir la documentation de Word2vec). Si nécessaire, procédez progressivement, en commençant par utiliser 1% du corpus, puis 10%, etc., pour contrôler le temps nécessaire.\n",
    "- Veuillez indiquer la dimension choisie pour le embedding de ce nouveau modèle.\n",
    "- Combien de temps prend l’entraînement sur le corpus total ?\n",
    "- Quelle est la taille (en Mo) du modèle word2vec résultant ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f05a5383",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4cc87605b005171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entraînement avec 1% du corpus :\n",
      "Temps d'entraînement : 1.54 secondes\n",
      "Taille du modèle : 3.18 Mo\n",
      "\n",
      "Entraînement avec 10% du corpus :\n",
      "Temps d'entraînement : 17.54 secondes\n",
      "Taille du modèle : 15.41 Mo\n",
      "\n",
      "Entraînement avec 100% du corpus :\n",
      "Temps d'entraînement : 223.43 secondes\n",
      "Taille du modèle : 56.47 Mo\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "corpus_sizes = [0.01, 0.1, 1.0]\n",
    "for size in corpus_sizes:\n",
    "    print(f\"\\nEntraînement avec {int(size * 100)}% du corpus :\")\n",
    "    subset = sentences[:int(len(sentences) * size)]\n",
    "\n",
    "    start_time = time.time()\n",
    "    model = Word2Vec(sentences=subset, vector_size=embedding_dim, window=5, min_count=5, sg=1, epochs=10)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    model_file = f\"text8_word2vec_{int(size * 100)}.model\"\n",
    "    model.save(model_file)\n",
    "    \n",
    "    model_size_mb = os.path.getsize(model_file) / (1024 * 1024)\n",
    "    \n",
    "    print(f\"Temps d'entraînement : {training_time:.2f} secondes\")\n",
    "    print(f\"Taille du modèle : {model_size_mb:.2f} Mo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c5caa8",
   "metadata": {},
   "source": [
    "### c. Mesurez la qualité de ce modèle comme en (1g) et (1h). Ce modèle est-il meilleur que celui entraîné sur Google News ? Quelle est selon vous la raison de la différence ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29ce80f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation: 0.6776 (p-value: 1.6706526799189313e-48)\n",
      "Spearman correlation: 0.6906 (p-value: 4.667657820285376e-51)\n",
      "OOV ratio: 0.5666\n",
      "Score : 0.33280978291355806\n"
     ]
    }
   ],
   "source": [
    "wordsim353_sim = model.wv.evaluate_word_pairs(datapath(\"wordsim353.tsv\"))\n",
    "print(f\"Pearson correlation: {wordsim353_sim[0][0]:.4f} (p-value: {wordsim353_sim[0][1]})\")\n",
    "print(f\"Spearman correlation: {wordsim353_sim[1][0]:.4f} (p-value: {wordsim353_sim[1][1]})\")\n",
    "print(f\"OOV ratio: {wordsim353_sim[2]:.4f}\")\n",
    "\n",
    "analogy_scores = model.wv.evaluate_word_analogies(datapath('questions-words.txt'))\n",
    "print(\"Score :\", analogy_scores[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ace6c20",
   "metadata": {},
   "source": [
    "> Le modèle présente une corrélation de Pearson (0,6776) et de Spearman (0,6906) légèrement meilleures que le modèle Google News sur WordSimilarity-353, mais un score d'analogies (0,3328) bien inférieur. Cela s'explique par le fait que votre modèle couvre moins de vocabulaire (OOV de 56,66%), ce qui limite sa performance sur les analogies. Le modèle Google News est entraîné sur un très grand corpus de textes variés, il offre donc une couverture de vocabulaire bien plus large et des représentations vectorielles plus robustes, ce qui améliore sa capacité à résoudre les analogies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24342035",
   "metadata": {},
   "source": [
    "### d. Téléchargez maintenant le corpus quatre fois plus grand constitué de la concaténation du corpus text8 et des dépêches économiques de Reuters fourni par l’enseignant et appelé wikipedia_augmented.zip (à décompresser en un fichier ‘.dat’ de 413 Mo). Entraînez un nouveau modèle word2vec sur ce corpus, en précisant la dimension choisie pour les embeddings.\n",
    "- Utilisez la classe Text8Corpus() pour charger ce corpus, ce qui fera automatiquement la\n",
    "tokenisation et la segmentation en phrases.\n",
    "- Combien de temps prend l’entraînement ?\n",
    "- Quelle est la taille (en Mo) du modèle word2vec résultant ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ea6dcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Text8Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8151986f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'entraînement : 1040.42 secondes\n",
      "Taille du modèle : 3.71 Mo\n"
     ]
    }
   ],
   "source": [
    "corpus_path = \"wikipedia_augmented.dat\"\n",
    "corpus = Text8Corpus(corpus_path)\n",
    "\n",
    "embedding_dim = 100\n",
    "\n",
    "start_time = time.time()\n",
    "new_model = Word2Vec(sentences=corpus, vector_size=embedding_dim, window=5, min_count=5, sg=1, epochs=10)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "model_file = \"wikipedia_augmented_word2vec.model\"\n",
    "new_model.save(model_file)\n",
    "\n",
    "model_size_mb = os.path.getsize(model_file) / (1024 * 1024)\n",
    "\n",
    "print(f\"Temps d'entraînement : {training_time:.2f} secondes\")\n",
    "print(f\"Taille du modèle : {model_size_mb:.2f} Mo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf08136",
   "metadata": {},
   "source": [
    "> Le temps d'entraînement est de 17 minutes et demi à peu près et la taille est de 3,71 Mo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de4eeb259fd1f9a",
   "metadata": {},
   "source": [
    "### e. Testez ce modèle comme en (1g) et (1h). Est-il meilleur que le précédent ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52768fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation: 0.5434 (p-value: 1.6618050648021703e-28)\n",
      "Spearman correlation: 0.5427 (p-value: 1.9899612315550654e-28)\n",
      "OOV ratio: 0.0000\n",
      "Score : 0.35854905373069396\n"
     ]
    }
   ],
   "source": [
    "wordsim353_sim = new_model.wv.evaluate_word_pairs(datapath(\"wordsim353.tsv\"))\n",
    "print(f\"Pearson correlation: {wordsim353_sim[0][0]:.4f} (p-value: {wordsim353_sim[0][1]})\")\n",
    "print(f\"Spearman correlation: {wordsim353_sim[1][0]:.4f} (p-value: {wordsim353_sim[1][1]})\")\n",
    "print(f\"OOV ratio: {wordsim353_sim[2]:.4f}\")\n",
    "\n",
    "analogy_scores = new_model.wv.evaluate_word_analogies(datapath('questions-words.txt'))\n",
    "print(\"Score :\", analogy_scores[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df78c50f",
   "metadata": {},
   "source": [
    "| Modèle                  | Pearson Correlation | Spearman Correlation | OOV Ratio |\n",
    "| ----------------------- | ------------------- | -------------------- | --------- |\n",
    "| Modèle 1 (w2v\\_vectors) | 0.6239 (p=0.0000)   | 0.6589 (p=0.0000)    | 0.00%     |\n",
    "| Modèle 2 (model)        | 0.6776 (p≈0.00)     | 0.6906 (p≈0.00)      | 56.66%    |\n",
    "| Corpus Wikipedia (new\\_model)   | 0.5434 (p≈0.00)     | 0.5427 (p≈0.00)      | 0.00%     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1658ab87",
   "metadata": {},
   "source": [
    "> Le Modèle 2 (petit corpus) obtient les meilleures performances en similarité de mots avec des corrélations de Pearson (0,6776) et de Spearman (0,6906), mais il souffre d'un taux élevé de mots hors vocabulaire (OOV) de 56,66 %, ce qui limite son efficacité. Le Modèle wikipedia a une couverture complète du vocabulaire (0 % OOV) et un score d'analogie supérieur (0,3585) par rapport au Modèle 2 (0,3328), mais ses performances de similarité sont plus faibles (Pearson : 0,5434, Spearman : 0,5427). Le Modèle pré-entraîné est un compromis avec une couverture complète (0 % OOV) et des performances de similarité décentes (Pearson : 0,6239, Spearman : 0,6589). En résumé, le Modèle 2 (petit corpus) excelle en similarité mais manque de couverture, tandis que le corpus wikipedia combine couverture et bonnes performances en analogies, ce qui le rend plus polyvalent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29956c3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
