{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Labo 5 Modèle word2vec et ses applications",
   "id": "cbcc0bd83bb1f042"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Tester et évaluer un modèle déjà entraîné sur Google News\n",
    "\n",
    "Veuillez télécharger le modèle word2vec pré-entraîné sur le corpus Google News en écrivant :\n",
    "```python\n",
    "from gensim import downloader as api\n",
    "w2v_vectors = api.load(\"word2vec-google-news-300\")\n",
    "```\n",
    "ce qui téléchargera le fichier la première fois.\n",
    "Après avoir téléchargé le modèle, vous pourrez l’utiliser ainsi (dans le dossier gensim-data) :\n",
    "```python\n",
    "from gensim.models import KeyedVectors\n",
    "w2v_vectors = KeyedVectors.load_word2vec_format(path_to_file, binary=True).\n",
    "```"
   ],
   "id": "9c7fbbc1e9dccc7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from gensim import downloader as api\n",
    "w2v_vectors = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "w2v_vectors = KeyedVectors.load_word2vec_format(path_to_file, binary=True)."
   ],
   "id": "4530a77693e4874d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### a. Quelle place en mémoire occupe le processus du notebook avec les vecteurs de mots ?\n",
    "### b. Quelle est la dimension de l’espace vectoriel dans lequel les mots sont représentés ?\n",
    "### c. Quelle est la taille du vocabulaire connu du modèle ? Veuillez afficher cinq mots anglais qui sont dans le vocabulaire et deux qui ne le sont pas.\n",
    "### d. Quelle est la similarité entre les mots rabbit et carrot ? Veuillez rappeler comment on mesure les similarités entre deux mots grâce à leurs vecteurs.\n",
    "### e. Considérez au moins 5 paires de mots anglais, certains proches par leurs sens, d’autres plus éloignés. Pour chaque paire, calculez la similarité entre les deux mots. Veuillez indiquer si les similarités obtenues correspondent à vos intuitions sur la proximité des sens des mots.\n",
    "### f. Pouvez-vous trouver des mots de sens opposés mais qui sont proches selon le modèle ? Comment expliquez-vous cela ? Est-ce une qualité ou un défaut du modèle word2vec ?\n",
    "### g. En vous aidant de la documentation de Gensim sur KeyedVectors, obtenez les scores du modèle word2vec sur les données de test WordSimilarity-353. Veuillez rappeler en 1-2 phrases comment les différents scores sont calculés.\n",
    "### h. En vous aidant de la documentation, calculez le score du modèle word2vec sur les données questions-words.txt. Attention, cette évaluation prend une dizaine de minutes, donc il vaut mieux commencer par tester avec un fragment de ce fichier (copier/coller les 100 premières analogies). Expliquez en 1-2 phrases comment ce score est calculé et ce qu’il mesure."
   ],
   "id": "c3ec3e208878055c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Entraîner deux nouveaux modèles word2vec à partir de deux corpus",
   "id": "98b61a019db22f42"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### a. En utilisant gensim.downloader (voir question 1) récupérez le corpus qui contient les 108 premiers caractères de Wikipédia (en anglais) avec la commande : corpus = api.load('text8'). Combien de phrases et de mots (tokens) possède ce corpus ?\n",
    "### b. Entraînez un nouveau modèle word2vec sur ce nouveau corpus (voir la documentation de Word2vec). Si nécessaire, procédez progressivement, en commençant par utiliser 1% du corpus, puis 10%, etc., pour contrôler le temps nécessaire.\n",
    "- Veuillez indiquer la dimension choisie pour le embedding de ce nouveau modèle.\n",
    "- Combien de temps prend l’entraînement sur le corpus total ?\n",
    "- Quelle est la taille (en Mo) du modèle word2vec résultant ?\n",
    "### c. Mesurez la qualité de ce modèle comme en (1g) et (1h). Ce modèle est-il meilleur que celui entraîné sur Google News ? Quelle est selon vous la raison de la différence ?\n",
    "### d. Téléchargez maintenant le corpus quatre fois plus grand constitué de la concaténation du corpus text8 et des dépêches économiques de Reuters fourni par l’enseignant et appelé wikipedia_augmented.zip (à décompresser en un fichier ‘.dat’ de 413 Mo). Entraînez un nouveau modèle word2vec sur ce corpus, en précisant la dimension choisie pour les embeddings.\n",
    "- Utilisez la classe Text8Corpus() pour charger ce corpus, ce qui fera automatiquement la\n",
    "tokenisation et la segmentation en phrases.\n",
    "- Combien de temps prend l’entraînement ?\n",
    "- Quelle est la taille (en Mo) du modèle word2vec résultant ?\n",
    "### e. Testez ce modèle comme en (1g) et (1h). Est-il meilleur que le précédent ?"
   ],
   "id": "6de4eeb259fd1f9a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
