{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://heig-vd.ch/docs/default-source/doc-global-newsletter/2020-slim.svg\" alt=\"HEIG-VD Logo\" width=\"100\" align=\"right\" /> \n",
    "\n",
    "# TAL Labo 1c : Op√©rations sur une page web en anglais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objectif** \n",
    "\n",
    "Dans cette troisi√®me partie du Labo1, vous allez refaire une partie des traitements de la partie 1b, mais cette fois-ci sur une page web, sp√©cifiquement une page Wikipedia en anglais (suggestion : \"Switzerland\").  L'objectif est de r√©viser les principales commandes apprises, et de traiter le format HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "from urllib import request\n",
    "import matplotlib.pyplot \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** S'inspirer du [chapitre 3 du livre NLTK](http://www.nltk.org/book/ch03.html) pour faire une requ√™te et r√©cup√©rer le contenu de la page indiqu√©e dans `url2`.  Quelle est la longueur de la cha√Æne de caract√®res obtenue ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1036302"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url2 = \"https://en.wikipedia.org/wiki/Switzerland\" \n",
    "response2 = request.urlopen(url2)\n",
    "html2 = response2.read().decode('utf8')\n",
    "len(html2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utilserons l'outil `BeautifulSoup` disponible sous forme de module Python pour extraire tout le texte de la page HTML.  Si le code source de la page est stock√© dans `html2`, on extrait le texte dans `raw2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = BeautifulSoup(html2).get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Veuillez r√©utiliser la m√©thode du _notebook_ 1b pour enlever le d√©but et la fin de la cha√Æne `raw2`, car ils contiennent du texte qui n'est pas pertinent pour notre analyse (il ne parle pas de la Suisse).  Quelle est la longueur du r√©sultat ?  Veuillez afficher ses 100 premiers et 100 derniers caract√®res."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98093"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start2 = text2.find(\"Switzerland\")\n",
    "end2 = text2.find(\"produced in Ticino\")\n",
    "clean_text2 = text2[start2:end2]\n",
    "len(clean_text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Veuillez effectuer la segmentation en phrases, puis tokeniser chaque phrase.  Veuillez √©crire le r√©sultat (une phrase par ligne, espaces entre *tokens*) dans un fichier `sample_web_page.txt` et inspectez-le avec un √©diteur de texte.  Observez-vous des imperfections ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"sample_web_page.txt\"\n",
    "sentences = sent_tokenize(clean_text2)\n",
    "# Pour un fichier local : chemin relatif par rapport au notebook\n",
    "# Pour Google Colab, p.ex.: /content/gdrive/My Drive/sample_web_page.txt\n",
    "if os.path.exists(filename): \n",
    "    os.remove(filename)\n",
    "with open(filename, 'a', encoding='utf8') as fd:\n",
    "    for sentence in sentences:\n",
    "        tokens = word_tokenize(sentence)\n",
    "        fd.write(\" \".join(tokens) + \"\\n\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre appr√©ciation de la qualit√© ici :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** Veuillez maintenant effectuer la tokenisation de cette page **sans** faire de segmentation en phrases.  Stockez le r√©sultat dans une variable (p.ex. `words2`) sans √©crire de fichier.  Combien de tokens poss√®de ce texte ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17963"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words2 = word_tokenize(clean_text2)\n",
    "len(words2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.** Veuillez cr√©er un objet de type `nltk.Text` √† partir de la liste de *tokens* `words2`.\n",
    "* D√©terminez le vocabulaire de cette page (la liste des _types_) en convertissant cet objet en un `set`.  \n",
    "* Combien de mots diff√©rents y a-t-il dans le vocabulaire, incluant les ponctuations et tout autre symbole ? \n",
    "* Quels sont les 20 types les plus longs ? Que pensez-vous du r√©sultat trouv√© ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IndonesiaInterlinguaInterlingue–ò—Ä–æ–ΩIsiXhosa√çslenskaItaliano◊¢◊ë◊®◊ô◊™JawaKab…©y…õ‡≤ï‡≤®‡≥ç‡≤®‡≤°Kapampangan–ö—ä–∞—Ä–∞—á–∞–π-–º–∞–ª–∫—ä–∞—Ä·É•·Éê·É†·Éó·É£·Éö·ÉòKasz√´bsczi“ö–∞–∑–∞“õ—à–∞KernowekIkinyarwandaIkirundiKiswahili–ö–æ–º–∏KongoKotavaKrey√≤l',\n",
       " \"Ac√®h–ê–¥—ã–≥—ç–±–∑—ç–ê–¥—ã–≥–∞–±–∑—çAfrikaansAlemannisch·ä†·àõ·à≠·äõAnar√¢≈°kiel√¢‡§Ö‡§Ç‡§ó‡§ø‡§ï‡§æ√Ünglisc–ê‘•—Å—à”ô–∞ÿßŸÑÿπÿ±ÿ®Ÿäÿ©Aragon√©s‹ê‹™‹°‹ù‹ê‘±÷Ä’•÷Ç’¥’ø’°’∞’°’µ’•÷Ä’ß’∂Arm√£neashtiArpetan‡¶Ö‡¶∏‡¶Æ‡ßÄ‡¶Ø‡¶º‡¶æAsturianu‡§Ö‡§µ‡§ß‡•ÄAva√±e'·∫Ω–ê–≤–∞—ÄAymar\",\n",
       " 'gwiyannenKurd√Æ–ö—ã—Ä–≥—ã–∑—á–∞LadinLadino‡∫•‡∫≤‡∫ßLatgaƒºuLatinaLatvie≈°uL√´tzebuergesch–õ–µ–∑–≥–∏Lietuvi≈≥LigureLimburgsLing√°laLingua',\n",
       " 'ZamboangaChi-ChewaChiShonaChiTumbukaCorsuCymraegDagbanliDanskÿßŸÑÿØÿßÿ±ÿ¨ÿ©Davvis√°megiellaDeitschDeutschﬁãﬁ®ﬁàﬁ¨ﬁÄﬁ®ﬁÑﬁ¶ﬁêﬁ∞Din√©',\n",
       " 'HindiF√∏roysktFran√ßaisFryskFulfuldeFurlanGaeilgeGaelgGagauzG√†idhligGalego–ì”Ä–∞–ª–≥”Ä–∞–πGƒ©k≈©y≈©⁄Ø€åŸÑ⁄©€å‡™ó‡´Å‡™ú‡™∞‡™æ‡™§‡´Äêå≤êåøêçÑêåπêçÉêå∫‡§ó‡•ã‡§Ç‡§Ø‡§ö‡•Ä',\n",
       " 'Vi·ªátVolap√ºkV√µroWalonÊñáË®ÄWest-VlamsWinarayWolofÂê¥ËØ≠Xitsonga◊ô◊ô÷¥◊ì◊ô◊©Yor√πb√°Á≤µË™ûZazakiZe√™uws≈Ωemaitƒó≈°ka‰∏≠ÊñáOboloBetawiBatak',\n",
       " '.lojban.LugandaLombardMagyarMadhur√¢‡§Æ‡•à‡§•‡§ø‡§≤‡•Ä–ú–∞–∫–µ–¥–æ–Ω—Å–∫–∏Malagasy‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥ÇMaltiMƒÅori‡§Æ‡§∞‡§æ‡§†‡•Ä·Éõ·Éê·É†·Éí·Éê·Éö·É£·É†·ÉòŸÖÿµÿ±ŸâŸÖÿßÿ≤Ÿêÿ±ŸàŸÜ€åBahasa',\n",
       " 'CentralBislama–ë—ä–ª–≥–∞—Ä—Å–∫–∏Boarisch‡Ωñ‡Ωº‡Ωë‡ºã‡Ω°‡Ω≤‡ΩÇBosanskiBrezhoneg–ë—É—Ä—è–∞–¥Catal√†–ß”ë–≤–∞—à–ª–∞Cebuanoƒåe≈°tinaChamoruChavacano',\n",
       " 'Hak-k√¢-ng√Æ–•–∞–ª—å–º–≥ÌïúÍµ≠Ïñ¥HausaHawai ªi’Ä’°’µ’•÷Ä’•’∂‡§π‡§ø‡§®‡•ç‡§¶‡•ÄHornjoserbsceHrvatskiIdoIgboIlokano‡¶¨‡¶ø‡¶∑‡ßç‡¶£‡ßÅ‡¶™‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ',\n",
       " 'PisinPlattd√º√ºtschPolskiŒ†ŒøŒΩœÑŒπŒ±Œ∫Œ¨Portugu√™sQaraqalpaqshaQƒ±rƒ±mtatarcaRipoarischRom√¢nƒÉRomani',\n",
       " '—û–∑–±–µ–∫—á–∞‡®™‡©∞‡®ú‡®æ‡®¨‡©Ä‡§™‡§æ‡§≤‡§øP√§lzischPangasinanPangcahŸæŸÜÿ¨ÿßÿ®€å·Äï·Ä°·Ä≠·ÄØ·Äù·Ä∫·Çè·Äò·Ä¨·Çè·Äû·Ä¨·ÇèPapiamentuŸæ⁄öÿ™ŸàPatois–ü–µ—Ä–µ–º',\n",
       " 'M√¨ng-dƒïÃ§ng-ng·π≥ÃÑMirand√©s–ú–æ–∫—à–µ–Ω—å–ú–æ–Ω–≥–æ–ª·Äô·Äº·Äî·Ä∫·Äô·Ä¨·Äò·Ä¨·Äû·Ä¨NederlandsNedersaksies‡§®‡•á‡§™‡§æ‡§≤‡•Ä‡§®‡•á‡§™‡§æ‡§≤',\n",
       " '—Å—Ä–ø—Å–∫–æ—Ö—Ä–≤–∞—Ç—Å–∫–∏SundaSuomiSvenskaTagalog‡Æ§‡ÆÆ‡Æø‡Æ¥‡ØçTacl·∏•itTaqbaylitTarand√≠ne–¢–∞—Ç–∞—Ä—á–∞',\n",
       " 'rumagn√≤l–≠—Ä–∑—è–Ω—åEspa√±olEsperantoEstreme√±uEuskaraE ãegbeŸÅÿßÿ±ÿ≥€åFiji',\n",
       " 'Samoa‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§Æ‡•ç·±•·±ü·±±·±õ·±ü·±≤·±§ÿ≥ÿ±ÿßÿ¶€å⁄©€åSarduScotsSeediqSeelterskSesotho',\n",
       " 'faka-Tonga·è£·é≥·é©Tsets√™hest√¢hese‡≤§‡≥Å‡≤≥‡≥ÅT√ºrk√ßeT√ºrkmen√ßeTyap–¢—ã–≤–∞',\n",
       " 'Englishÿ≥ŸÜ⁄åŸäSiSwatiSlovenƒçinaSloven≈°ƒçina–°–ª–æ–≤—£–Ω—å—Å–∫—ä',\n",
       " 'bizaadDolnoserbski‡§°‡•ã‡§ü‡•á‡§≤‡•Ä‡Ωá‡Ωº‡ΩÑ‡ºã‡ΩÅEestiŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨Emili√†n',\n",
       " '‚∞î‚∞é‚∞ë‚∞Ç‚∞°‚∞ê‚∞†‚∞î‚∞ç‚∞ü≈öl≈ØnskiSoomaaliga⁄©Ÿàÿ±ÿØ€åSranantongo–°—Ä–ø—Å–∫–∏',\n",
       " 'languagesGermanFrenchItalianRomanshReligion']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = nltk.Text(words2)\n",
    "vocab2 = set(text2)\n",
    "len(vocab2)\n",
    "longest_words2 = sorted(vocab2, key=len, reverse=True)[:20]\n",
    "longest_words2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre r√©ponse √† la question ici :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.** Veuillez construire un objet `FreqDist` avec les mots de cette page, en convertissant en minuscules tous les mots contenant seulement des lettres (utilisez la m√©thode `.isalpha()` de Python).  Quels sont les 30 mots les plus fr√©quents ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 1155),\n",
       " ('of', 561),\n",
       " ('and', 470),\n",
       " ('in', 467),\n",
       " ('to', 238),\n",
       " ('switzerland', 229),\n",
       " ('swiss', 189),\n",
       " ('a', 178),\n",
       " ('is', 151),\n",
       " ('as', 103),\n",
       " ('federal', 102),\n",
       " ('by', 92),\n",
       " ('for', 91),\n",
       " ('are', 87),\n",
       " ('was', 85),\n",
       " ('with', 78),\n",
       " ('from', 71),\n",
       " ('it', 61),\n",
       " ('world', 52),\n",
       " ('at', 49),\n",
       " ('has', 47),\n",
       " ('on', 46),\n",
       " ('most', 44),\n",
       " ('its', 44),\n",
       " ('main', 41),\n",
       " ('other', 41),\n",
       " ('one', 41),\n",
       " ('an', 41),\n",
       " ('cantons', 39),\n",
       " ('population', 39)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words2 = [word.lower() for word in words2 if word.isalpha()]\n",
    "freqdist2 = FreqDist(words2)\n",
    "most_common2 = freqdist2.most_common(30)\n",
    "most_common2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.** Veuillez afficher le graphique cumulatif du nombre d'occurrences des 70 mots les plus fr√©quents de votre texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 1155),\n",
       " ('of', 561),\n",
       " ('and', 470),\n",
       " ('in', 467),\n",
       " ('to', 238),\n",
       " ('switzerland', 229),\n",
       " ('swiss', 189),\n",
       " ('a', 178),\n",
       " ('is', 151),\n",
       " ('as', 103),\n",
       " ('federal', 102),\n",
       " ('by', 92),\n",
       " ('for', 91),\n",
       " ('are', 87),\n",
       " ('was', 85),\n",
       " ('with', 78),\n",
       " ('from', 71),\n",
       " ('it', 61),\n",
       " ('world', 52),\n",
       " ('at', 49),\n",
       " ('has', 47),\n",
       " ('on', 46),\n",
       " ('most', 44),\n",
       " ('its', 44),\n",
       " ('main', 41),\n",
       " ('other', 41),\n",
       " ('one', 41),\n",
       " ('an', 41),\n",
       " ('cantons', 39),\n",
       " ('population', 39),\n",
       " ('that', 37),\n",
       " ('european', 36),\n",
       " ('international', 35),\n",
       " ('country', 35),\n",
       " ('or', 33),\n",
       " ('zurich', 33),\n",
       " ('geneva', 33),\n",
       " ('were', 32),\n",
       " ('largest', 31),\n",
       " ('which', 29),\n",
       " ('among', 28),\n",
       " ('countries', 28),\n",
       " ('canton', 28),\n",
       " ('council', 27),\n",
       " ('german', 27),\n",
       " ('war', 27),\n",
       " ('french', 26),\n",
       " ('than', 26),\n",
       " ('but', 26),\n",
       " ('article', 26),\n",
       " ('their', 26),\n",
       " ('also', 25),\n",
       " ('first', 25),\n",
       " ('while', 25),\n",
       " ('alps', 24),\n",
       " ('not', 24),\n",
       " ('per', 23),\n",
       " ('national', 23),\n",
       " ('such', 23),\n",
       " ('constitution', 23),\n",
       " ('century', 23),\n",
       " ('about', 23),\n",
       " ('europe', 22),\n",
       " ('bern', 22),\n",
       " ('between', 22),\n",
       " ('after', 22),\n",
       " ('government', 21),\n",
       " ('confederation', 21),\n",
       " ('have', 21),\n",
       " ('this', 20)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common2 = freqdist2.most_common(70)\n",
    "most_common2 = dict(most_common2)\n",
    "most_common2 = sorted(most_common2.items(), key=lambda x: x[1], reverse=True)\n",
    "most_common2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.** Veuillez construire une liste avec la longueur de chaque token du texte, cr√©ez un nouvel objet `FreqDist` √† partir de cette liste, et affichez la distribution (non-cumulative) des nombres d'occurrences pour chaque longueur.  Qu'observez-vous ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez √©crire votre code ci-dessous, puis ex√©cuter cette cellule.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre r√©ponse √† la question ici :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin de la partie 1c du Labo1\n",
    "Veuillez nettoyer autant que possible ce _notebook_, ex√©cutez une derni√®re fois toutes les cellules pour obtenir les r√©sultats demand√©s, et enregistrez le _notebook_ sous le nom `TAL_labo1c_NOM1_NOM2.ipynb`.  Ajoutez-le dans une archive _zip_ avec le _notebook_ 1b, et soumettez l'archive individuellement sur Cyberlearn. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
