{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://heig-vd.ch/docs/default-source/doc-global-newsletter/2020-slim.svg\" alt=\"HEIG-VD Logo\" width=\"100\" align=\"right\" /> \n",
    "\n",
    "# TAL Labo 1c : Opérations sur une page web en anglais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objectif** \n",
    "\n",
    "Dans cette troisième partie du Labo1, vous allez refaire une partie des traitements de la partie 1b, mais cette fois-ci sur une page web, spécifiquement une page Wikipedia en anglais (suggestion : \"Switzerland\").  L'objectif est de réviser les principales commandes apprises, et de traiter le format HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "from urllib import request\n",
    "import matplotlib.pyplot \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** S'inspirer du [chapitre 3 du livre NLTK](http://www.nltk.org/book/ch03.html) pour faire une requête et récupérer le contenu de la page indiquée dans `url2`.  Quelle est la longueur de la chaîne de caractères obtenue ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1036302"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url2 = \"https://en.wikipedia.org/wiki/Switzerland\" \n",
    "response2 = request.urlopen(url2)\n",
    "html2 = response2.read().decode('utf8')\n",
    "len(html2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utilserons l'outil `BeautifulSoup` disponible sous forme de module Python pour extraire tout le texte de la page HTML.  Si le code source de la page est stocké dans `html2`, on extrait le texte dans `raw2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = BeautifulSoup(html2).get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Veuillez réutiliser la méthode du _notebook_ 1b pour enlever le début et la fin de la chaîne `raw2`, car ils contiennent du texte qui n'est pas pertinent pour notre analyse (il ne parle pas de la Suisse).  Quelle est la longueur du résultat ?  Veuillez afficher ses 100 premiers et 100 derniers caractères."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98093"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start2 = text2.find(\"Switzerland\")\n",
    "end2 = text2.find(\"produced in Ticino\")\n",
    "clean_text2 = text2[start2:end2]\n",
    "len(clean_text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Veuillez effectuer la segmentation en phrases, puis tokeniser chaque phrase.  Veuillez écrire le résultat (une phrase par ligne, espaces entre *tokens*) dans un fichier `sample_web_page.txt` et inspectez-le avec un éditeur de texte.  Observez-vous des imperfections ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"sample_web_page.txt\"\n",
    "sentences = sent_tokenize(clean_text2)\n",
    "# Pour un fichier local : chemin relatif par rapport au notebook\n",
    "# Pour Google Colab, p.ex.: /content/gdrive/My Drive/sample_web_page.txt\n",
    "if os.path.exists(filename): \n",
    "    os.remove(filename)\n",
    "with open(filename, 'a', encoding='utf8') as fd:\n",
    "    for sentence in sentences:\n",
    "        tokens = word_tokenize(sentence)\n",
    "        fd.write(\" \".join(tokens) + \"\\n\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre appréciation de la qualité ici :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** Veuillez maintenant effectuer la tokenisation de cette page **sans** faire de segmentation en phrases.  Stockez le résultat dans une variable (p.ex. `words2`) sans écrire de fichier.  Combien de tokens possède ce texte ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17963"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words2 = word_tokenize(clean_text2)\n",
    "len(words2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.** Veuillez créer un objet de type `nltk.Text` à partir de la liste de *tokens* `words2`.\n",
    "* Déterminez le vocabulaire de cette page (la liste des _types_) en convertissant cet objet en un `set`.  \n",
    "* Combien de mots différents y a-t-il dans le vocabulaire, incluant les ponctuations et tout autre symbole ? \n",
    "* Quels sont les 20 types les plus longs ? Que pensez-vous du résultat trouvé ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IndonesiaInterlinguaInterlingueИронIsiXhosaÍslenskaItalianoעבריתJawaKabɩyɛಕನ್ನಡKapampanganКъарачай-малкъарქართულიKaszëbscziҚазақшаKernowekIkinyarwandaIkirundiKiswahiliКомиKongoKotavaKreyòl',\n",
       " \"AcèhАдыгэбзэАдыгабзэAfrikaansAlemannischአማርኛAnarâškielâअंगिकाÆngliscАԥсшәаالعربيةAragonésܐܪܡܝܐԱրեւմտահայերէնArmãneashtiArpetanঅসমীয়াAsturianuअवधीAvañe'ẽАварAymar\",\n",
       " 'gwiyannenKurdîКыргызчаLadinLadinoລາວLatgaļuLatinaLatviešuLëtzebuergeschЛезгиLietuviųLigureLimburgsLingálaLingua',\n",
       " 'ZamboangaChi-ChewaChiShonaChiTumbukaCorsuCymraegDagbanliDanskالدارجةDavvisámegiellaDeitschDeutschދިވެހިބަސްDiné',\n",
       " 'HindiFøroysktFrançaisFryskFulfuldeFurlanGaeilgeGaelgGagauzGàidhligGalegoГӀалгӀайGĩkũyũگیلکیગુજરાતી𐌲𐌿𐍄𐌹𐍃𐌺गोंयची',\n",
       " 'ViệtVolapükVõroWalon文言West-VlamsWinarayWolof吴语XitsongaייִדישYorùbá粵語ZazakiZeêuwsŽemaitėška中文OboloBetawiBatak',\n",
       " '.lojban.LugandaLombardMagyarMadhurâमैथिलीМакедонскиMalagasyമലയാളംMaltiMāoriमराठीმარგალურიمصرىمازِرونیBahasa',\n",
       " 'CentralBislamaБългарскиBoarischབོད་ཡིགBosanskiBrezhonegБуряадCatalàЧӑвашлаCebuanoČeštinaChamoruChavacano',\n",
       " 'Hak-kâ-ngîХальмг한국어HausaHawaiʻiՀայերենहिन्दीHornjoserbsceHrvatskiIdoIgboIlokanoবিষ্ণুপ্রিয়া',\n",
       " 'PisinPlattdüütschPolskiΠοντιακάPortuguêsQaraqalpaqshaQırımtatarcaRipoarischRomânăRomani',\n",
       " 'ўзбекчаਪੰਜਾਬੀपालिPälzischPangasinanPangcahپنجابیပအိုဝ်ႏဘာႏသာႏPapiamentuپښتوPatoisПерем',\n",
       " 'Mìng-dĕ̤ng-ngṳ̄MirandésМокшеньМонголမြန်မာဘာသာNederlandsNedersaksiesनेपालीनेपाल',\n",
       " 'српскохрватскиSundaSuomiSvenskaTagalogதமிழ்TaclḥitTaqbaylitTarandíneТатарча',\n",
       " 'rumagnòlЭрзяньEspañolEsperantoEstremeñuEuskaraEʋegbeفارسیFiji',\n",
       " 'Samoaसंस्कृतम्ᱥᱟᱱᱛᱟᱲᱤسرائیکیSarduScotsSeediqSeelterskSesotho',\n",
       " 'faka-TongaᏣᎳᎩTsetsêhestâheseತುಳುTürkçeTürkmençeTyapТыва',\n",
       " 'EnglishسنڌيSiSwatiSlovenčinaSlovenščinaСловѣньскъ',\n",
       " 'bizaadDolnoserbskiडोटेलीཇོང་ཁEestiΕλληνικάEmiliàn',\n",
       " 'ⰔⰎⰑⰂⰡⰐⰠⰔⰍⰟŚlůnskiSoomaaligaکوردیSranantongoСрпски',\n",
       " 'languagesGermanFrenchItalianRomanshReligion']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = nltk.Text(words2)\n",
    "vocab2 = set(text2)\n",
    "len(vocab2)\n",
    "longest_words2 = sorted(vocab2, key=len, reverse=True)[:20]\n",
    "longest_words2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre réponse à la question ici :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.** Veuillez construire un objet `FreqDist` avec les mots de cette page, en convertissant en minuscules tous les mots contenant seulement des lettres (utilisez la méthode `.isalpha()` de Python).  Quels sont les 30 mots les plus fréquents ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 1155),\n",
       " ('of', 561),\n",
       " ('and', 470),\n",
       " ('in', 467),\n",
       " ('to', 238),\n",
       " ('switzerland', 229),\n",
       " ('swiss', 189),\n",
       " ('a', 178),\n",
       " ('is', 151),\n",
       " ('as', 103),\n",
       " ('federal', 102),\n",
       " ('by', 92),\n",
       " ('for', 91),\n",
       " ('are', 87),\n",
       " ('was', 85),\n",
       " ('with', 78),\n",
       " ('from', 71),\n",
       " ('it', 61),\n",
       " ('world', 52),\n",
       " ('at', 49),\n",
       " ('has', 47),\n",
       " ('on', 46),\n",
       " ('most', 44),\n",
       " ('its', 44),\n",
       " ('main', 41),\n",
       " ('other', 41),\n",
       " ('one', 41),\n",
       " ('an', 41),\n",
       " ('cantons', 39),\n",
       " ('population', 39)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words2 = [word.lower() for word in words2 if word.isalpha()]\n",
    "freqdist2 = FreqDist(words2)\n",
    "most_common2 = freqdist2.most_common(30)\n",
    "most_common2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.** Veuillez afficher le graphique cumulatif du nombre d'occurrences des 70 mots les plus fréquents de votre texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 1155),\n",
       " ('of', 561),\n",
       " ('and', 470),\n",
       " ('in', 467),\n",
       " ('to', 238),\n",
       " ('switzerland', 229),\n",
       " ('swiss', 189),\n",
       " ('a', 178),\n",
       " ('is', 151),\n",
       " ('as', 103),\n",
       " ('federal', 102),\n",
       " ('by', 92),\n",
       " ('for', 91),\n",
       " ('are', 87),\n",
       " ('was', 85),\n",
       " ('with', 78),\n",
       " ('from', 71),\n",
       " ('it', 61),\n",
       " ('world', 52),\n",
       " ('at', 49),\n",
       " ('has', 47),\n",
       " ('on', 46),\n",
       " ('most', 44),\n",
       " ('its', 44),\n",
       " ('main', 41),\n",
       " ('other', 41),\n",
       " ('one', 41),\n",
       " ('an', 41),\n",
       " ('cantons', 39),\n",
       " ('population', 39),\n",
       " ('that', 37),\n",
       " ('european', 36),\n",
       " ('international', 35),\n",
       " ('country', 35),\n",
       " ('or', 33),\n",
       " ('zurich', 33),\n",
       " ('geneva', 33),\n",
       " ('were', 32),\n",
       " ('largest', 31),\n",
       " ('which', 29),\n",
       " ('among', 28),\n",
       " ('countries', 28),\n",
       " ('canton', 28),\n",
       " ('council', 27),\n",
       " ('german', 27),\n",
       " ('war', 27),\n",
       " ('french', 26),\n",
       " ('than', 26),\n",
       " ('but', 26),\n",
       " ('article', 26),\n",
       " ('their', 26),\n",
       " ('also', 25),\n",
       " ('first', 25),\n",
       " ('while', 25),\n",
       " ('alps', 24),\n",
       " ('not', 24),\n",
       " ('per', 23),\n",
       " ('national', 23),\n",
       " ('such', 23),\n",
       " ('constitution', 23),\n",
       " ('century', 23),\n",
       " ('about', 23),\n",
       " ('europe', 22),\n",
       " ('bern', 22),\n",
       " ('between', 22),\n",
       " ('after', 22),\n",
       " ('government', 21),\n",
       " ('confederation', 21),\n",
       " ('have', 21),\n",
       " ('this', 20)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common2 = freqdist2.most_common(70)\n",
    "most_common2 = dict(most_common2)\n",
    "most_common2 = sorted(most_common2.items(), key=lambda x: x[1], reverse=True)\n",
    "most_common2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.** Veuillez construire une liste avec la longueur de chaque token du texte, créez un nouvel objet `FreqDist` à partir de cette liste, et affichez la distribution (non-cumulative) des nombres d'occurrences pour chaque longueur.  Qu'observez-vous ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre réponse à la question ici :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin de la partie 1c du Labo1\n",
    "Veuillez nettoyer autant que possible ce _notebook_, exécutez une dernière fois toutes les cellules pour obtenir les résultats demandés, et enregistrez le _notebook_ sous le nom `TAL_labo1c_NOM1_NOM2.ipynb`.  Ajoutez-le dans une archive _zip_ avec le _notebook_ 1b, et soumettez l'archive individuellement sur Cyberlearn. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
